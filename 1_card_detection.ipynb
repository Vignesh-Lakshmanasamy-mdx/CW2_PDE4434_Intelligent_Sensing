{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe71795c-f79c-4389-9196-d8cd36ed1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color detection\n",
    "def detect_card_color(img):\n",
    "    \"\"\" Determining the color of the card using HSV color space \"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # color ranges for UNO colors\n",
    "    colors = {\n",
    "        \"Red\": ([0, 120, 70], [10, 255, 255]),\n",
    "        \"Yellow\": ([20, 100, 100], [30, 255, 255]),\n",
    "        \"Green\": ([35, 100, 100], [85, 255, 255]),\n",
    "        \"Blue\": ([90, 100, 100], [130, 255, 255])\n",
    "    }\n",
    "\n",
    "    for color, (lower, upper) in colors.items():\n",
    "        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "        if cv2.countNonZero(mask) > 500:  # If enough pixels match the color\n",
    "            return color\n",
    "\n",
    "    return \"unknown\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f1c31e-7c6c-4763-9155-f7c9337df3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 , math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"uno_number_detection.keras\")\n",
    "\n",
    "# Define categories\n",
    "categories = [\"Number_1\", \"Number_2\", \"Number_3\",\"Number_4\",\"Number_5\",\"Number_6\",\"Number_7\",\"Number_8\",\"Number_9\",\"Symbol_Draw_2\",\"Symbol_Reverse\",\"Symbol_Skip\"]\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width and height\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    #copying the origianl image\n",
    "   \n",
    "\n",
    "    img_size=224\n",
    "\n",
    "    #preprocessing cycle -1 :\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#converting to gray scale\n",
    "    _, thresh = cv2.threshold(gray,200, 255, cv2.THRESH_BINARY) #thresholding the image\n",
    "    edges = cv2.Canny(thresh, 100, 200)# edge detection\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8) #matrix size for dilation and eroding 5 x 5\n",
    "\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=2) #dilation\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1) #erosion\n",
    "    \n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # finds the contour\n",
    "    \n",
    "    cv2.drawContours(frame, contours, -1, (0, 255, 0), 3) # draw a contour around the uno card\n",
    "    \n",
    "    img_input=frame.copy()\n",
    "    copy_image=frame.copy()\n",
    "    \n",
    "    for contour in contours:\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "\n",
    "        box = cv2.boxPoints(rect) # creating the box points\n",
    "        box = box.astype(int) # getting the x, y value for each cornor points\n",
    "        \n",
    "        cv2.drawContours(img_input, [box], -1, (255, 0, 0), 3) # drawing a box\n",
    "\n",
    "    #calculating the center point\n",
    "    center_x = int(np.mean(box[:, 0]))\n",
    "    center_y = int(np.mean(box[:, 1]))\n",
    "\n",
    "    # Draw the center point\n",
    "    cv2.circle(img_input, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "    pt1, pt2, pt3, pt4 = box #four points of the rectangle\n",
    "\n",
    "    # midpoint of pt1 - pt2\n",
    "    mid1 = ((pt1[0] + pt2[0]) // 2, (pt1[1] + pt2[1]) // 2)\n",
    "    \n",
    "    # midpoint of pt3 - pt4\n",
    "    mid2 = ((pt3[0] + pt4[0]) // 2, (pt3[1] + pt4[1]) // 2)\n",
    "    \n",
    "    #midpoint of pt1 - pt4\n",
    "    mid3=((pt1[0] + pt4[0]) // 2, (pt1[1] + pt4[1]) // 2)\n",
    "    \n",
    "    #midpoint of pt2 - pt3\n",
    "    mid4 = ((pt3[0] + pt2[0]) // 2, (pt3[1] + pt2[1]) // 2)\n",
    "\n",
    "    # Draw the line between midpoints\n",
    "    cv2.line(img_input, mid1, mid2, (255, 255, 0), 2)  \n",
    "    cv2.line(img_input, mid3, mid4, (0, 255, 0), 2)\n",
    "    \n",
    "    #distance between points or length of the line\n",
    "    line1_length=math.sqrt((mid2[0] - mid1[0])**2+(mid2[1] - mid1[1])**2)\n",
    "    line2_length=math.sqrt((mid4[0] - mid3[0])**2+(mid4[1] - mid3[1])**2)\n",
    "\n",
    "    #finding the longest line and setting those mid point to take angle\n",
    "    if line1_length>line2_length:\n",
    "        midpoint1=mid1\n",
    "        midpoint2=mid2\n",
    "    else:\n",
    "        midpoint1=mid3\n",
    "        midpoint2=mid4\n",
    "        \n",
    "    # length of reference line\n",
    "    line_length = 100\n",
    "    \n",
    "    # Starting point is center\n",
    "    start_point = (center_x, center_y)\n",
    "    \n",
    "    # End point straight up (90 degrees)\n",
    "    end_point = (center_x, center_y - line_length)\n",
    "    \n",
    "    # Drawing the vertical reference line\n",
    "    cv2.line(img_input, start_point, end_point, (0, 255, 255), 2)  # Yellow line\n",
    "                    \n",
    "    # Vector of midpoint line\n",
    "    vector_x = midpoint2[0] - midpoint1[0]\n",
    "    vector_y = midpoint2[1] - midpoint1[1]\n",
    "    \n",
    "    # Angle between vector and vertical line (0, -1)\n",
    "    angle_rad = np.arctan2(vector_y, vector_x) - np.arctan2(-1, 0)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    angle_deg = angle_deg % 360 \n",
    "                    \n",
    "    # Getting image center\n",
    "    (h, w) = img_input.shape[:2]\n",
    "    image_center = (w // 2, h // 2)\n",
    "    \n",
    "    # rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(image_center, angle_deg, 1.0)\n",
    "    \n",
    "    # Perform the rotation\n",
    "    rotated = cv2.warpAffine(copy_image, M, (w, h))\n",
    "    #show_image(rotated, \"Rotated image\")\n",
    "    \n",
    "    # preprocessing - cycle2\n",
    "\n",
    "    gray_2 = cv2.cvtColor(rotated, cv2.COLOR_BGR2GRAY) \n",
    "    _, thresh_2 = cv2.threshold(gray_2,220, 255, cv2.THRESH_BINARY)             \n",
    "    edges_2 = cv2.Canny(thresh_2, 100, 200)\n",
    "                  \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    \n",
    "    dilated_2 = cv2.dilate(edges_2, kernel, iterations=2)\n",
    "    eroded_2 = cv2.erode(dilated_2, kernel, iterations=1)\n",
    "    \n",
    "    contours, _ = cv2.findContours(eroded_2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Process only if we have at least one valid contour\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(rotated, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        \n",
    "        \n",
    "        if area > 500:  # Filter small areas\n",
    "                                   \n",
    "            cropped = rotated[y:y+h, x:x+w]                       \n",
    "            resize_img = cv2.resize(cropped, (224, 224))\n",
    "            \n",
    "            # preprocessing - cycle3\n",
    "            \n",
    "            gray_3 = cv2.cvtColor(resize_img, cv2.COLOR_BGR2GRAY)                       \n",
    "            _, thresh_3 = cv2.threshold(gray_3,220, 255, cv2.THRESH_BINARY)\n",
    "            edges_3 = cv2.Canny(thresh_3, 100, 200)\n",
    "            \n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            \n",
    "            dilated_3 = cv2.dilate(edges_3, kernel, iterations=2)\n",
    "            eroded_3 = cv2.erode(dilated_3, kernel, iterations=1)\n",
    "            \n",
    "            contours, _ = cv2.findContours(thresh_3, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for cnt in contours:\n",
    "                area2 = cv2.contourArea(cnt)\n",
    "                \n",
    "                \n",
    "                if area2> 19000 and area2 <30000:\n",
    "                                        \n",
    "                    background = np.ones((224, 224, 3), dtype=np.uint8) * 255  \n",
    "                    \n",
    "                    # Creating mask for the oval contour\n",
    "                    mask = np.zeros_like(resize_img)\n",
    "                    cv2.drawContours(mask, [cnt], 0, (255, 255, 255), -1)\n",
    "                                                   \n",
    "                    # Applying mask to extract oval region\n",
    "                    masked = cv2.bitwise_and(resize_img, mask)\n",
    "                    \n",
    "                    # Crop the contour region\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    cropped = masked[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Get shape of cropped region\n",
    "                    ch, cw = cropped.shape[:2]\n",
    "    \n",
    "                    target_size = 224\n",
    "                    # Compute offsets to center it\n",
    "                    x_offset = (target_size - cw) // 2\n",
    "                    y_offset = (target_size - ch) // 2\n",
    "                    \n",
    "                    # Pasting cropped oval into the center of white background\n",
    "                    background[y_offset:y_offset+ch, x_offset:x_offset+cw] = cropped\n",
    "    \n",
    "                    #final_crop=cv2.cvtColor(background, cv2.COLOR_BGR2RGB)\n",
    "                    gray_final = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "                    _, thresh_final = cv2.threshold(gray_final,226, 255, cv2.THRESH_BINARY)\n",
    "                    #show_image(thresh_final,\"final - image\",cmap=\"grey\")\n",
    "\n",
    "                    # Resize to final model input size\n",
    "                    final_img = cv2.resize(thresh_final, (img_size, img_size))\n",
    "    \n",
    "                    # Preprocess the image\n",
    "                    img_processed = preprocess_input(final_img.astype(np.float32))\n",
    "                    img_array = np.expand_dims(img_processed, axis=0)\n",
    "\n",
    "                    predictions = model.predict(img_array, verbose=0)\n",
    "                    class_id = np.argmax(predictions)\n",
    "                    confidence = np.max(predictions)\n",
    "\n",
    "                    label = f\"{categories[class_id]}\"\n",
    "\n",
    "                    color = detect_card_color(background)\n",
    "\n",
    "                cv2.putText(frame,\"Label -\"+label,(10, 30),cv2.FONT_HERSHEY_SIMPLEX,1,(0, 255, 0),1,cv2.LINE_AA)\n",
    "                cv2.putText(frame,\"Color -\"+color,(30, 60),cv2.FONT_HERSHEY_SIMPLEX,1,(0, 255, 0),1,cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "    # Show video feed\n",
    "    cv2.imshow(\"Live Detection\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9dd48-edf3-4f73-8300-bddc3c0e54b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c168c-36ea-4f68-9718-2cfca74cc324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
