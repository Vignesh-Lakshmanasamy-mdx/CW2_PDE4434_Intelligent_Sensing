{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0f18f5-5214-4098-ae88-ebc220c057ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_1(img):\n",
    "\n",
    "    background=img.copy()\n",
    "    rotated_list=[]\n",
    "    #preprocessing cycle -1 :\n",
    "    gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)#converting to gray scale\n",
    "    _, thresh = cv2.threshold(gray,200, 255, cv2.THRESH_BINARY) #thresholding the image\n",
    "    edges = cv2.Canny(thresh, 100, 200)# edge detection\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8) #matrix size for dilation and eroding 5 x 5\n",
    "\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=2) #dilation\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1) #erosion\n",
    "    \n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # finds the contour\n",
    "    cv2.drawContours(background, contours, -1, (0, 255, 0), 3) # draw a contour around the uno card\n",
    "    #show_image(background,\"cropped\",cmap=\"grey\")\n",
    "    \n",
    "    for contour in contours:\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "\n",
    "        box = cv2.boxPoints(rect) # creating the box points\n",
    "        box = box.astype(int) # getting the x, y value for each cornor points\n",
    "        \n",
    "        cv2.drawContours(background, [box], -1, (255, 0, 0), 3) # drawing a box\n",
    "\n",
    "        #calculating the center point\n",
    "        center_x = int(np.mean(box[:, 0]))\n",
    "        center_y = int(np.mean(box[:, 1]))\n",
    "    \n",
    "        # Draw the center point\n",
    "        cv2.circle(background, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "    \n",
    "        pt1, pt2, pt3, pt4 = box #four points of the rectangle\n",
    "    \n",
    "        # midpoint of pt1 - pt2\n",
    "        mid1 = ((pt1[0] + pt2[0]) // 2, (pt1[1] + pt2[1]) // 2)\n",
    "        \n",
    "        # midpoint of pt3 - pt4\n",
    "        mid2 = ((pt3[0] + pt4[0]) // 2, (pt3[1] + pt4[1]) // 2)\n",
    "        \n",
    "        #midpoint of pt1 - pt4\n",
    "        mid3=((pt1[0] + pt4[0]) // 2, (pt1[1] + pt4[1]) // 2)\n",
    "        \n",
    "        #midpoint of pt2 - pt3\n",
    "        mid4 = ((pt3[0] + pt2[0]) // 2, (pt3[1] + pt2[1]) // 2)\n",
    "    \n",
    "        # Draw the line between midpoints\n",
    "        cv2.line(background, mid1, mid2, (255, 255, 0), 2)  \n",
    "        cv2.line(background, mid3, mid4, (0, 255, 0), 2)\n",
    "        \n",
    "        #distance between points or length of the line\n",
    "        line1_length=math.sqrt((mid2[0] - mid1[0])**2+(mid2[1] - mid1[1])**2)\n",
    "        line2_length=math.sqrt((mid4[0] - mid3[0])**2+(mid4[1] - mid3[1])**2)\n",
    "    \n",
    "        #finding the longest line and setting those mid point to take angle\n",
    "        if line1_length>line2_length:\n",
    "            midpoint1=mid1\n",
    "            midpoint2=mid2\n",
    "        else:\n",
    "            midpoint1=mid3\n",
    "            midpoint2=mid4\n",
    "            \n",
    "        # length of reference line\n",
    "        line_length = 100\n",
    "        \n",
    "        # Starting point is center\n",
    "        start_point = (center_x, center_y)\n",
    "        \n",
    "        # End point straight up (90 degrees)\n",
    "        end_point = (center_x, center_y - line_length)\n",
    "        \n",
    "        # Drawing the vertical reference line\n",
    "        cv2.line(background, start_point, end_point, (0, 255, 255), 2)  # Yellow line\n",
    "                        \n",
    "        # Vector of midpoint line\n",
    "        vector_x = midpoint2[0] - midpoint1[0]\n",
    "        vector_y = midpoint2[1] - midpoint1[1]\n",
    "        \n",
    "        # Angle between vector and vertical line (0, -1)\n",
    "        angle_rad = np.arctan2(vector_y, vector_x) - np.arctan2(-1, 0)\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "        angle_deg = angle_deg % 360 \n",
    "                        \n",
    "        # Getting image center\n",
    "        (h, w) = background.shape[:2]\n",
    "        image_center = (w // 2, h // 2)\n",
    "        \n",
    "        # rotation matrix\n",
    "        M = cv2.getRotationMatrix2D(image_center, angle_deg, 1.0)\n",
    "        \n",
    "        # Perform the rotation\n",
    "        rotated = cv2.warpAffine(background_copy, M, (w, h))\n",
    "        #show_image(background,\"cropped\",cmap=\"grey\")\n",
    "        #show_image(rotated, \"Rotated image\")\n",
    "        rotated_list.append(rotated)\n",
    "    return rotated_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1faa1450-fee2-4ad4-88fc-e22b34c42754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_2(img):\n",
    "\n",
    "    rotated=img.copy()\n",
    "    final_img=[]\n",
    "    # preprocessing - cycle2\n",
    "\n",
    "    gray_2 = cv2.cvtColor(rotated, cv2.COLOR_BGR2GRAY) \n",
    "    _, thresh_2 = cv2.threshold(gray_2,220, 255, cv2.THRESH_BINARY)             \n",
    "    edges_2 = cv2.Canny(thresh_2, 100, 200)\n",
    "                  \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    \n",
    "    dilated_2 = cv2.dilate(edges_2, kernel, iterations=2)\n",
    "    eroded_2 = cv2.erode(dilated_2, kernel, iterations=1)\n",
    "    \n",
    "    contours, _ = cv2.findContours(eroded_2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Process only if we have at least one valid contour\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(rotated, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        \n",
    "        \n",
    "        if area > 500:  # Filter small areas\n",
    "                                   \n",
    "            cropped = rotated[y:y+h, x:x+w]                       \n",
    "            resize_img = cv2.resize(cropped, (224, 224))\n",
    "            \n",
    "            # preprocessing - cycle3\n",
    "            \n",
    "            gray_3 = cv2.cvtColor(resize_img, cv2.COLOR_BGR2GRAY)                       \n",
    "            _, thresh_3 = cv2.threshold(gray_3,220, 255, cv2.THRESH_BINARY)\n",
    "            edges_3 = cv2.Canny(thresh_3, 100, 200)\n",
    "            \n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            \n",
    "            dilated_3 = cv2.dilate(edges_3, kernel, iterations=2)\n",
    "            eroded_3 = cv2.erode(dilated_3, kernel, iterations=1)\n",
    "            \n",
    "            contours, _ = cv2.findContours(thresh_3, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for cnt in contours:\n",
    "                area2 = cv2.contourArea(cnt)\n",
    "                \n",
    "                \n",
    "                if area2> 19000 and area2 <30000:\n",
    "                                        \n",
    "                    background = np.ones((224, 224, 3), dtype=np.uint8) * 255  \n",
    "                    \n",
    "                    # Creating mask for the oval contour\n",
    "                    mask = np.zeros_like(resize_img)\n",
    "                    cv2.drawContours(mask, [cnt], 0, (255, 255, 255), -1)\n",
    "                                                   \n",
    "                    # Applying mask to extract oval region\n",
    "                    masked = cv2.bitwise_and(resize_img, mask)\n",
    "                    \n",
    "                    # Crop the contour region\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    cropped = masked[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Get shape of cropped region\n",
    "                    ch, cw = cropped.shape[:2]\n",
    "    \n",
    "                    target_size = 224\n",
    "                    # Compute offsets to center it\n",
    "                    x_offset = (target_size - cw) // 2\n",
    "                    y_offset = (target_size - ch) // 2\n",
    "                    \n",
    "                    # Pasting cropped oval into the center of white background\n",
    "                    background[y_offset:y_offset+ch, x_offset:x_offset+cw] = cropped\n",
    "\n",
    "                    \n",
    "                    #final_crop=cv2.cvtColor(background, cv2.COLOR_BGR2RGB)\n",
    "                    gray_final = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "                    _, thresh_final = cv2.threshold(gray_final,226, 255, cv2.THRESH_BINARY)\n",
    "                    #show_image(thresh_final,\"final - image\",cmap=\"grey\")\n",
    "\n",
    "                    # Resize to final model input size\n",
    "                    #final_img = cv2.resize(thresh_final, (img_size, img_size))\n",
    "                    final_img.append(thresh_final)\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68c39075-39a2-48be-b3ed-0e2b5a53e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 , math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"uno_number_detection.keras\")\n",
    "\n",
    "# Define categories\n",
    "categories = [\"Number_1\", \"Number_2\", \"Number_3\",\"Number_4\",\"Number_5\",\"Number_6\",\"Number_7\",\"Number_8\",\"Number_9\",\"Symbol_Draw_2\",\"Symbol_Reverse\",\"Symbol_Skip\"]\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width and height\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    edges = cv2.Canny(thresh, 100, 200)\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "    contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 2500:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # Draw contour rectangle\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "            # Crop from original image\n",
    "            cropped = frame[y:y+h, x:x+w]\n",
    "\n",
    "            output_h, output_w = 640, 480\n",
    "            background = np.zeros((output_h, output_w, 3), dtype=np.uint8)\n",
    "\n",
    "            ch, cw = cropped.shape[:2]\n",
    "            if ch <= output_h and cw <= output_w:\n",
    "                y_offset = (output_h - ch) // 2\n",
    "                x_offset = (output_w - cw) // 2\n",
    "                background[y_offset:y_offset+ch, x_offset:x_offset+cw] = cropped\n",
    "            #show_image(background,\"cropped\",cmap=\"grey\")\n",
    "                background_copy=background.copy()\n",
    "\n",
    "                rotated_img=preprocessing_1(background)\n",
    "                for allrotated in rotated_img:\n",
    "                    \n",
    "                    predict_img=preprocessing_2(allrotated)\n",
    "\n",
    "                    for allimages in predict_img:\n",
    "                        #show_image(allimages, \"final image for prediction\")\n",
    "                        final_img = cv2.resize(allimages, (224, 224))\n",
    "                        # Preprocess the image\n",
    "                        img_processed = preprocess_input(final_img.astype(np.float32))\n",
    "                        img_array = np.expand_dims(img_processed, axis=0)\n",
    "    \n",
    "                        predictions = model.predict(img_array, verbose=0)\n",
    "                        class_id = np.argmax(predictions)\n",
    "                        confidence = np.max(predictions)\n",
    "                    \n",
    "                        # Draw rectangle and label\n",
    "                        label = f\"{categories[class_id]}\"#\" ({confidence * 100:.2f}%)\" \n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            \n",
    "    # Show video feed\n",
    "    cv2.imshow(\"Live Detection\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26cff8c7-d4c0-4144-b022-e12859a16c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(img, title=\"Image\", cmap=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3a2ec-2c52-4cd6-bb57-d1d3301a6da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6226d-b8ef-46c7-b763-9842226a78ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
